{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ“˜ GET TO KNOW A DATASET: ivrit-ai Hebrew Audio v2\n"
      ],
      "metadata": {
        "id": "pCKe8wY12c91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§© 1. Introduction\n",
        "\n",
        "This notebook provides a practical introduction to the ivrit-ai Hebrew Audio v2 dataset.\n",
        "It shows how to explore the dataset when stored in a local directory, how to inspect sources, compute basic statistics, and listen to individual recordings.\n",
        "\n",
        "The dataset is a large, curated collection of Hebrew audio files gathered from diverse public sources (podcasts, YouTube channels, radio archives, and other institutional material).\n",
        "It is distributed via [Hugging Face](https://huggingface.co/datasets/ivrit-ai/audio-v2)"
      ],
      "metadata": {
        "id": "_Y4W7JSt2jpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¦ 2. Folder Structure Assumed in This Notebook\n",
        "We assume the dataset is stored locally in a directory with the following structure:\n",
        "\n",
        "```\n",
        "data_root/\n",
        "    source_A/\n",
        "        file1.mp3\n",
        "        file2.wav\n",
        "        ...\n",
        "    source_B/\n",
        "        clip3.m4a\n",
        "        clip4.opus\n",
        "        ...\n",
        "    ...\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "*   Each source is placed in its own folder.\n",
        "\n",
        "*   Each folder contains raw audio files in arbitrary formats (.mp3, .m4a, .opus, .wav, etc.)\n",
        "* No additional metadata is required for the tasks below.\n",
        "\n",
        "Set your dataset path here:\n",
        "\n"
      ],
      "metadata": {
        "id": "j6cHk8bx2pxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEtzZhmz2YNN"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/path/to/ivrit-ai-audio-v2\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”§ 3. Setup"
      ],
      "metadata": {
        "id": "BVPmTRIw3c62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Audio, display\n"
      ],
      "metadata": {
        "id": "zJFfmnKv3gTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ 4. Enumerate Sources and Audio Files"
      ],
      "metadata": {
        "id": "ZIn_7PUH3iVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = Path(\"/path/to/ivrit-ai-audio-v2\")\n",
        "\n",
        "sources = [p for p in DATA_ROOT.iterdir() if p.is_dir()]\n",
        "print(\"Number of sources:\", len(sources))\n",
        "sources[:10]\n"
      ],
      "metadata": {
        "id": "9csooKjv3k2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”¢ 5. Count Audio Files per Source"
      ],
      "metadata": {
        "id": "DvP9ijQE3ndv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_exts = {\".mp3\", \".wav\", \".m4a\", \".opus\", \".flac\"}\n",
        "\n",
        "def list_audio_files(folder):\n",
        "    return [f for f in folder.iterdir() if f.suffix.lower() in audio_exts]\n",
        "\n",
        "records = []\n",
        "for source in sources:\n",
        "    files = list_audio_files(source)\n",
        "    records.append({\n",
        "        \"source\": source.name,\n",
        "        \"num_files\": len(files)\n",
        "    })\n",
        "\n",
        "df_counts = pd.DataFrame(records).sort_values(\"num_files\", ascending=False)\n",
        "df_counts.head()\n"
      ],
      "metadata": {
        "id": "QrI0iR-83pST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â±ï¸ 6. Calculate Total Duration per Source\n",
        "\n",
        "This loads only metadata from audio headers â€” not full audio into memory."
      ],
      "metadata": {
        "id": "9D33LaCR3rQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_duration(path):\n",
        "    try:\n",
        "        return librosa.get_duration(path=path)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "duration_records = []\n",
        "\n",
        "for source in sources:\n",
        "    files = list_audio_files(source)\n",
        "    for f in files:\n",
        "        duration_records.append({\n",
        "            \"source\": source.name,\n",
        "            \"file\": f.name,\n",
        "            \"path\": f,\n",
        "            \"duration_s\": get_duration(f)\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(duration_records)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "NAGEoKbL3uHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group by Source"
      ],
      "metadata": {
        "id": "BQjp6vmo30PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_source = (\n",
        "    df.groupby(\"source\")[\"duration_s\"]\n",
        "      .agg([\"count\", \"sum\", \"mean\"])\n",
        "      .rename(columns={\"count\": \"num_files\", \"sum\": \"total_hours\", \"mean\": \"avg_sec\"})\n",
        ")\n",
        "\n",
        "df_source[\"total_hours\"] = df_source[\"total_hours\"] / 3600\n",
        "df_source.head()\n"
      ],
      "metadata": {
        "id": "qumnJ9vX31LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Total dataset duration"
      ],
      "metadata": {
        "id": "Hi31UJMv3452"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_hours = df[\"duration_s\"].sum() / 3600\n",
        "total_hours\n"
      ],
      "metadata": {
        "id": "3-xOC3Vh35xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â–¶ï¸ 7. Play a Specific Audio File"
      ],
      "metadata": {
        "id": "_tG292Mw37ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_source = df.iloc[0][\"source\"]\n",
        "example_path = df.iloc[0][\"path\"]\n",
        "\n",
        "print(\"Source:\", example_source)\n",
        "print(\"File:\", example_path.name)\n",
        "\n",
        "display(Audio(str(example_path)))\n"
      ],
      "metadata": {
        "id": "tiwE_dX939kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š 8. Plot a Waveform + Spectrogram"
      ],
      "metadata": {
        "id": "OprCxcTN4AcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y, sr = librosa.load(example_path, sr=None)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.title(\"Waveform\")\n",
        "plt.plot(y)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.title(\"Spectrogram\")\n",
        "S = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "librosa.display.specshow(S, sr=sr, x_axis=\"time\", y_axis=\"hz\")\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z7XPS11B3_mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“˜ 9. Summary Table"
      ],
      "metadata": {
        "id": "jOg330D44G5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = {\n",
        "    \"num_sources\": len(df_source),\n",
        "    \"num_audio_files\": len(df),\n",
        "    \"total_hours\": total_hours\n",
        "}\n",
        "summary\n"
      ],
      "metadata": {
        "id": "A7s70O9s4Fib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## License\n",
        "This dataset is released under the ivrit.ai license, a modified CC-BY license permitting use for machine-learning model training while prohibiting deepfake generation and certain misuse scenarios.\n",
        "Full terms:\n",
        "https://www.ivrit.ai/en/license-faqs/\n",
        "\n",
        "## Citation\n",
        "If you use this dataset, cite:\n",
        "\n",
        "> Marmor, Yanir; Lifshitz, Yair; Snapir, Yoad; Misgav, Kinneret (2025). *Building an Accurate Open-Source Hebrew ASR System through Crowdsourcing*. Interspeech 2025.\n",
        "\n"
      ],
      "metadata": {
        "id": "ANCdhNqy4Tz0"
      }
    }
  ]
}